{"instruction": "What is the relationship between the two phrases 'dependency parsing of sentences' and 'ambiguity resolution of right-side dependencies'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  The ambiguity resolution of right-side dependencies is essential for dependency parsing of sentences with two or more verbs .", "output": "used-for"}
{"instruction": "What is the relationship between the two phrases 'resolving the right-side dependencies' and 'shift-reduce dependency parsers'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Previous works on shift-reduce dependency parsers may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right-side dependencies .", "output": "irrelevant"}
{"instruction": "What is the relationship between the two phrases 'SVM learning' and 'two-phase shift-reduce dependency parser'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  This paper proposes a two-phase shift-reduce dependency parser based on SVM learning .", "output": "part-of"}
{"instruction": "What is the relationship between the two phrases 'shift-reduce dependency parsers' and 'two-phase shift-reduce dependency parser'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Previous works on shift-reduce dependency parsers may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right-side dependencies .\tThis paper proposes a two-phase shift-reduce dependency parser based on SVM learning .", "output": "subclass-of"}
{"instruction": "What is the relationship between the two phrases 'dependency accuracy' and 'shift-reduce dependency parsers for the Chine language'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  In experimental evaluation , our proposed method outperforms previous shift-reduce dependency parsers for the Chine language , showing improvement of dependency accuracy by 10.08 % .", "output": "with-metric"}
{"instruction": "What is the relationship between the two phrases 'resolving the right-side dependencies' and 'shift-reduce dependency parsers'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Previous works on shift-reduce dependency parsers may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right-side dependencies .", "output": "irrelevant"}
{"instruction": "What is the relationship between the two phrases 'shift-reduce dependency parsers for the Chine language' and 'dependency accuracy'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  In experimental evaluation , our proposed method outperforms previous shift-reduce dependency parsers for the Chine language , showing improvement of dependency accuracy by 10.08 % .", "output": "irrelevant"}
{"instruction": "What is the relationship between the two phrases 'two-phase shift-reduce dependency parser' and 'SVM learning'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  This paper proposes a two-phase shift-reduce dependency parser based on SVM learning .", "output": "irrelevant"}
{"instruction": "What is the relationship between the two phrases 'building a non-English -LRB- Arabic -RRB- stemmer' and 'unsupervised learning approach'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  This paper presents an unsupervised learning approach to building a non-English -LRB- Arabic -RRB- stemmer .", "output": "used-for"}
{"instruction": "What is the relationship between the two phrases 'statistical machine translation' and 'stemming model'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  The stemming model is based on statistical machine translation and it uses an English stemmer and a small -LRB- 10K sentences -RRB- parallel corpus as its sole training resources .", "output": "part-of"}
{"instruction": "What is the relationship between the two phrases 'average precision' and 'proprietary stemmer'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Task-based evaluation using Arabic information retrieval indicates an improvement of 22-38 % in average precision over unstemmed text , and 96 % of the performance of the proprietary stemmer above .", "output": "with-metric"}
{"instruction": "What is the relationship between the two phrases 'Dutch Senseval-2 test data' and 'lemma-based model'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Testing the lemma-based model on the Dutch Senseval-2 test data , we achieve a significant increase in accuracy over the wordform model .", "output": "with-dataset"}
{"instruction": "What is the relationship between the two phrases 'reduce the computation' and 'compute the N-Best sentence hypotheses'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  We describe algorithms that greatly reduce the computation needed to compute the N-Best sentence hypotheses .", "output": "sequence-of"}
{"instruction": "What is the relationship between the two phrases 'unlexicalized PCFG parser' and 'PCFG-LA'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Because exact parsing with a PCFG-LA is NP-hard , several approximations are described and empirically compared .\tIn experiments using the Penn WSJ corpus , our automatically trained model gave a performance of 86.6 % -LRB- F1 , sentences < 40 words -RRB- , which is comparable to that of an unlexicalized PCFG parser created using extensive manual feature selection .", "output": "compare"}
{"instruction": "What is the relationship between the two phrases 'ranking algorithm' and 'enumeration'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  An efficient ranking algorithm is described , together with experimental results showing significant improvements over simple enumeration or a lattice-based approach .", "output": "directed-compare"}
{"instruction": "What is the relationship between the two phrases 'language model' and 'insufficient training data'?  (A) part-of (B) use (C) same (D) hypernym (E) approved (F) test (G) impact (H) compare (J) compare-direct (L) has-problem (M) none  Owing to the problem of insufficient training data and approximation error introduced by the language model , traditional statistical approaches , which resolve ambiguities by indirectly and implicitly using maximum likelihood method , fail to achieve high performance in real applications .", "output": "problem-exist"}
